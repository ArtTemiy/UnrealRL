{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import Serializer as srl\n",
    "import socket\n",
    "import tensorforce\n",
    "from tensorforce import Agent, Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PongEnvironment(Environment):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def states(self):\n",
    "        return dict(type='float', shape=(4,))\n",
    "\n",
    "    def actions(self):\n",
    "        return dict(type='int', num_values=3)\n",
    "\n",
    "    # Optional: should only be defined if environment has a natural fixed\n",
    "    # maximum episode length; restrict training timesteps via\n",
    "    #     Environment.create(..., max_episode_timesteps=???)\n",
    "    # def max_episode_timesteps(self):\n",
    "    #     return super().max_episode_timesteps()\n",
    "\n",
    "    # Optional additional steps to close environment\n",
    "    # def close(self):\n",
    "    #     super().close()\n",
    "\n",
    "    def reset(self):\n",
    "        # state = np.random.random(size=(8,))\n",
    "        # return state\n",
    "        pass\n",
    "\n",
    "    def execute(self, actions):\n",
    "        # next_state = np.random.random(size=(8,))\n",
    "        # terminal = np.random.random() < 0.5\n",
    "        # reward = np.random.random()\n",
    "        # return next_state, terminal, reward\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CreateAgent():\n",
    "    return Agent.create(\n",
    "    agent='ppo',\n",
    "    # environment=PongEnvironment(),  # alternatively: states, actions, (max_episode_timesteps),\n",
    "    states=dict(type='float', shape=(6,)),\n",
    "    actions=dict(type='int', num_values=3),\n",
    "    max_episode_timesteps=1000,\n",
    "    network='auto',\n",
    "    # PPO optimization parameters\n",
    "    batch_size=10, update_frequency=2, learning_rate=3e-4,\n",
    "    subsampling_fraction=0.33,\n",
    "    # Reward estimation\n",
    "    likelihood_ratio_clipping=0.2, discount=0.99,\n",
    "    # Preprocessing\n",
    "    preprocessing='linear_normalization',\n",
    "    # Exploration\n",
    "    exploration=0.0, variable_noise=0.0,\n",
    "    # Regularization\n",
    "    l2_regularization=0.0, entropy_regularization=0.0,\n",
    "    # Default additional config values\n",
    "    config=None,\n",
    "    # Log all available Tensorboard summaries\n",
    "    summarizer=dict(directory='summaries', labels='all'),\n",
    "    # Do not record agent-environment interaction trace\n",
    "    recorder=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Act(agent, conn):\n",
    "    obs = srl.DeserializeMessage(conn)\n",
    "#     print('obs:', obs)\n",
    "    act = agent.act(obs)\n",
    "#     print('message:', srl.SerializeInt(act))\n",
    "    conn.sendall(srl.SerializeInt(int(act) - 1).encode(FORMAT))\n",
    "#     print('acted:', act)\n",
    "    return act\n",
    "\n",
    "    \n",
    "def Learn(agent, conn):\n",
    "    reward, done = srl.DeserializeMessage(conn), bool(srl.DeserializeMessage(conn))\n",
    "    agent.observe(terminal=done, reward=reward)\n",
    "    return reward, done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:No min_value bound specified for state.\n",
      "WARNING:root:Policy type should be explicitly specified for non-standard agent configuration.\n",
      "WARNING:root:No min_value bound specified for state.\n",
      "WARNING:root:Policy type should be explicitly specified for non-standard agent configuration.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ok\n"
     ]
    }
   ],
   "source": [
    "AgentL, AgentR = CreateAgent(), CreateAgent()\n",
    "print('ok')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "waiting for L to connect\n",
      "L Connected by ('127.0.0.1', 51207)\n",
      "waiting for R to connect\n",
      "R Connected by ('127.0.0.1', 51208)\n",
      "epoch:    0\n",
      "rewards: -99976 100024\n",
      "epoch:    1\n",
      "rewards: 100069 -99931\n",
      "epoch:    2\n",
      "rewards: 100065 -99935\n",
      "epoch:    3\n",
      "rewards: 100044 -99956\n",
      "epoch:    4\n",
      "rewards: -99980 100020\n",
      "epoch:    5\n",
      "rewards: -99957 100043\n",
      "epoch:    6\n",
      "rewards: -99980 100020\n",
      "epoch:    7\n",
      "rewards: -99954 100046\n",
      "epoch:    8\n",
      "rewards: -99979 100021\n",
      "epoch:    9\n",
      "rewards: 100046 -99954\n",
      "epoch:   10\n",
      "rewards: 100021 -99979\n",
      "epoch:   11\n",
      "rewards: -99977 100023\n",
      "epoch:   12\n",
      "rewards: 100066 -99934\n",
      "epoch:   13\n",
      "rewards: -99952 100048\n",
      "epoch:   14\n",
      "rewards: 100065 -99935\n",
      "epoch:   15\n",
      "rewards: -99952 100048\n",
      "epoch:   16\n",
      "rewards: 100021 -99979\n",
      "epoch:   17\n",
      "rewards: 100022 -99978\n",
      "epoch:   18\n",
      "rewards: 100022 -99978\n",
      "epoch:   19\n",
      "rewards: 100022 -99978\n",
      "epoch:   20\n",
      "rewards: -99978 100022\n",
      "epoch:   21\n",
      "rewards: -99950 100050\n",
      "epoch:   22\n",
      "rewards: -99952 100048\n",
      "epoch:   23\n",
      "rewards: -99977 100023\n",
      "epoch:   24\n",
      "rewards: -99978 100022\n",
      "epoch:   25\n",
      "rewards: -99977 100023\n",
      "epoch:   26\n",
      "rewards: -99951 100049\n",
      "epoch:   27\n",
      "rewards: 100071 -99929\n",
      "epoch:   28\n",
      "rewards: -99978 100022\n",
      "epoch:   29\n",
      "rewards: 100024 -99976\n",
      "epoch:   30\n",
      "rewards: 100024 -99976\n",
      "epoch:   31\n",
      "rewards: 100023 -99977\n",
      "epoch:   32\n",
      "rewards: 100075 -99925\n",
      "epoch:   33\n",
      "rewards: 100024 -99976\n",
      "epoch:   34\n",
      "rewards: 100021 -99979\n",
      "epoch:   35\n",
      "rewards: -99926 100074\n",
      "epoch:   36\n",
      "rewards: -99946 100054\n",
      "epoch:   37\n",
      "rewards: 100025 -99975\n",
      "epoch:   38\n",
      "rewards: -99976 100024\n",
      "epoch:   39\n",
      "rewards: 100053 -99947\n",
      "epoch:   40\n",
      "rewards: -99975 100025\n",
      "epoch:   41\n",
      "rewards: 100023 -99977\n",
      "epoch:   42\n",
      "rewards: -99977 100023\n",
      "epoch:   43\n",
      "rewards: -99975 100025\n",
      "epoch:   44\n",
      "rewards: 100017 -99983\n",
      "epoch:   45\n",
      "rewards: 100054 -99946\n",
      "epoch:   46\n",
      "rewards: -99978 100022\n",
      "epoch:   47\n",
      "rewards: -99976 100024\n",
      "epoch:   48\n",
      "rewards: -99929 100071\n",
      "epoch:   49\n",
      "rewards: -99976 100024\n",
      "epoch:   50\n",
      "rewards: -99927 100073\n",
      "epoch:   51\n",
      "rewards: -99926 100074\n",
      "epoch:   52\n",
      "rewards: -99978 100022\n",
      "epoch:   53\n",
      "rewards: 100024 -99976\n",
      "epoch:   54\n",
      "rewards: -99978 100022\n",
      "epoch:   55\n",
      "rewards: -99947 100053\n",
      "epoch:   56\n",
      "rewards: -99958 100042\n",
      "epoch:   57\n",
      "rewards: -99965 100035\n",
      "epoch:   58\n",
      "rewards: 100020 -99980\n",
      "epoch:   59\n",
      "rewards: -99977 100023\n",
      "epoch:   60\n",
      "rewards: 100077 -99923\n",
      "epoch:   61\n",
      "rewards: -99974 100026\n",
      "epoch:   62\n",
      "rewards: 100025 -99975\n",
      "epoch:   63\n",
      "rewards: -99978 100022\n",
      "epoch:   64\n",
      "rewards: 100022 -99978\n",
      "epoch:   65\n",
      "rewards: -99976 100024\n",
      "epoch:   66\n",
      "rewards: -99979 100021\n",
      "epoch:   67\n",
      "rewards: -99977 100023\n",
      "epoch:   68\n",
      "rewards: -99953 100047\n",
      "epoch:   69\n",
      "rewards: -99951 100049\n",
      "epoch:   70\n",
      "rewards: 100103 -99897\n",
      "epoch:   71\n",
      "rewards: -99954 100046\n",
      "epoch:   72\n",
      "rewards: -99981 100019\n",
      "epoch:   73\n",
      "rewards: 100021 -99979\n",
      "epoch:   74\n",
      "rewards: 100086 -99914\n",
      "epoch:   75\n",
      "rewards: -99937 100063\n",
      "epoch:   76\n",
      "rewards: 100021 -99979\n",
      "epoch:   77\n",
      "rewards: -99980 100020\n",
      "epoch:   78\n",
      "rewards: 100021 -99979\n",
      "epoch:   79\n",
      "rewards: 100020 -99980\n",
      "epoch:   80\n",
      "rewards: -99938 100062\n",
      "epoch:   81\n",
      "rewards: -99980 100020\n",
      "epoch:   82\n",
      "rewards: -99978 100022\n",
      "epoch:   83\n",
      "rewards: -99955 100045\n",
      "epoch:   84\n",
      "rewards: -99931 100069\n",
      "epoch:   85\n",
      "rewards: 100023 -99977\n",
      "epoch:   86\n",
      "rewards: -99979 100021\n",
      "epoch:   87\n",
      "rewards: -99977 100023\n",
      "epoch:   88\n",
      "rewards: -99979 100021\n",
      "epoch:   89\n",
      "rewards: -99953 100047\n",
      "epoch:   90\n",
      "rewards: 100052 -99948\n",
      "epoch:   91\n",
      "rewards: -99976 100024\n",
      "epoch:   92\n",
      "rewards: -99978 100022\n",
      "epoch:   93\n",
      "rewards: -99948 100052\n",
      "epoch:   94\n",
      "rewards: 100023 -99977\n",
      "epoch:   95\n",
      "rewards: -99974 100026\n",
      "epoch:   96\n",
      "rewards: -99950 100050\n",
      "epoch:   97\n",
      "rewards: 100055 -99945\n",
      "epoch:   98\n",
      "rewards: -99979 100021\n",
      "epoch:   99\n",
      "rewards: -99949 100051\n",
      "epoch:  100\n",
      "rewards: 100023 -99977\n",
      "epoch:  101\n",
      "rewards: 100053 -99947\n",
      "epoch:  102\n",
      "rewards: 100052 -99948\n",
      "epoch:  103\n",
      "rewards: -99977 100023\n",
      "epoch:  104\n",
      "rewards: 100022 -99978\n",
      "epoch:  105\n",
      "rewards: 100023 -99977\n",
      "epoch:  106\n",
      "rewards: -99978 100022\n",
      "epoch:  107\n",
      "rewards: -99927 100073\n",
      "epoch:  108\n",
      "rewards: -99978 100022\n",
      "epoch:  109\n",
      "rewards: 100097 -99903\n",
      "epoch:  110\n",
      "rewards: -99977 100023\n",
      "epoch:  111\n",
      "rewards: -99977 100023\n",
      "epoch:  112\n",
      "rewards: -99951 100049\n",
      "epoch:  113\n",
      "rewards: -99978 100022\n",
      "epoch:  114\n",
      "rewards: -99949 100051\n",
      "epoch:  115\n",
      "rewards: -99976 100024\n",
      "epoch:  116\n",
      "rewards: -99951 100049\n",
      "epoch:  117\n",
      "rewards: -99923 100077\n",
      "epoch:  118\n",
      "rewards: -99949 100051\n",
      "epoch:  119\n",
      "rewards: -99948 100052\n",
      "epoch:  120\n",
      "rewards: 100024 -99976\n",
      "epoch:  121\n",
      "rewards: -99976 100024\n",
      "epoch:  122\n",
      "rewards: -99909 100091\n",
      "epoch:  123\n",
      "rewards: -99976 100024\n",
      "epoch:  124\n",
      "rewards: -99949 100051\n",
      "epoch:  125\n",
      "rewards: -99951 100049\n",
      "epoch:  126\n",
      "rewards: -99908 100092\n",
      "epoch:  127\n",
      "rewards: 100049 -99951\n",
      "epoch:  128\n",
      "rewards: 100063 -99937\n",
      "epoch:  129\n",
      "rewards: -99952 100048\n",
      "epoch:  130\n",
      "rewards: -99958 100042\n",
      "epoch:  131\n",
      "rewards: 100046 -99954\n",
      "epoch:  132\n",
      "rewards: -99933 100067\n",
      "epoch:  133\n",
      "rewards: -99954 100046\n",
      "epoch:  134\n",
      "rewards: -99956 100044\n",
      "epoch:  135\n",
      "rewards: -99977 100023\n",
      "epoch:  136\n",
      "rewards: -99934 100066\n",
      "epoch:  137\n",
      "rewards: -99982 100018\n",
      "epoch:  138\n",
      "rewards: -99978 100022\n",
      "epoch:  139\n",
      "rewards: -99956 100044\n",
      "epoch:  140\n",
      "rewards: 100042 -99958\n",
      "epoch:  141\n",
      "rewards: -99955 100045\n",
      "epoch:  142\n",
      "rewards: -99956 100044\n",
      "epoch:  143\n",
      "rewards: -99935 100065\n",
      "epoch:  144\n",
      "rewards: -99936 100064\n",
      "epoch:  145\n",
      "rewards: -99953 100047\n",
      "epoch:  146\n",
      "rewards: -99933 100067\n",
      "epoch:  147\n",
      "rewards: -99930 100070\n",
      "epoch:  148\n",
      "rewards: -99978 100022\n",
      "epoch:  149\n",
      "rewards: -99952 100048\n",
      "epoch:  150\n",
      "rewards: -99951 100049\n",
      "epoch:  151\n",
      "rewards: -99950 100050\n",
      "epoch:  152\n",
      "rewards: 100022 -99978\n",
      "epoch:  153\n",
      "rewards: -99951 100049\n",
      "epoch:  154\n",
      "rewards: -99978 100022\n",
      "epoch:  155\n",
      "rewards: -99949 100051\n",
      "epoch:  156\n",
      "rewards: -99977 100023\n",
      "epoch:  157\n",
      "rewards: -99975 100025\n",
      "epoch:  158\n",
      "rewards: 100077 -99923\n",
      "epoch:  159\n"
     ]
    }
   ],
   "source": [
    "HOST = '127.0.0.1'\n",
    "PORTL = 1488\n",
    "PORTR = 1489\n",
    "FORMAT = 'utf-8'\n",
    "\n",
    "with socket.socket(socket.AF_INET, socket.SOCK_STREAM) as s:\n",
    "    s.bind((HOST, PORTL))\n",
    "    print('waiting for L to connect')\n",
    "    s.listen()\n",
    "    connL, addrL = s.accept()\n",
    "    print('L Connected by', addrL)\n",
    "\n",
    "\n",
    "with socket.socket(socket.AF_INET, socket.SOCK_STREAM) as s:\n",
    "    s.bind((HOST, PORTR))\n",
    "    s.listen()\n",
    "    print('waiting for R to connect')\n",
    "    connR, addrR = s.accept()\n",
    "    print('R Connected by', addrR)\n",
    "\n",
    "EPOCH_NUM = 200\n",
    "for epoch in range(EPOCH_NUM):\n",
    "    print(f'epoch: {epoch: 4}')\n",
    "\n",
    "    doneL, doneR = False, False\n",
    "    rewardTotalL, rewardTotalR = 0, 0\n",
    "    while not (doneL or doneR):\n",
    "#         print('____________________')\n",
    "        actL = Act(AgentL, connL)\n",
    "#         print(f'actL {actL}')\n",
    "        actR = Act(AgentR, connR)\n",
    "#         print(f'actR {actR}')\n",
    "#         print('it ended')\n",
    "\n",
    "        rewardL, doneL = Learn(AgentL, connL)\n",
    "        rewardR, doneR = Learn(AgentR, connR)\n",
    "        rewardTotalL += rewardL\n",
    "        rewardTotalR += rewardR\n",
    "        \n",
    "    print(f'rewards: {rewardTotalL} {rewardTotalR}')\n",
    "#         print(f'done {doneL} {doneR}')\n",
    "\n",
    "connL.close()\n",
    "connR.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
